{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Juypter Notebook for Joe McGrath's submission for the Udacity Machine Learning Engineer nanodegree program.\n",
    "This file contains the relevant code-blocks, assiocated comments and visual aids to be used in conjunction with the written PDF piece.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intro code cell, in here the required libaries will be imported\n",
    "#Comments etc.\n",
    "#Data imported, results from other models saved for future reference\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#import visuals as vs\n",
    "%matplotlib inline\n",
    "#Plotting libaries\n",
    "#Machine Learning libaries \n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "#Summary statistics\n",
    "#Target variables\n",
    "#Double [[]] wrapping ensure stays as pandas dataframe\n",
    "targData=data[['critical_temp']]\n",
    "#Feature variables\n",
    "#Dropping the target variables from the data-set\n",
    "featData=data.drop(['critical_temp'],axis=1)\n",
    "##Such that we are left with only the extracted features from the material properties\n",
    "featData=featData.drop(['number_of_elements'],axis=1)\n",
    "#featData.describe().transpose()\n",
    "\n",
    "#Data Transformation\n",
    "#Applying lograthmic and Scaling to the data-set prior to training/testing\n",
    "#Applying lograthmic transformation to the data-set\n",
    "#cols=list(featData)\n",
    "#featData[cols] = featData[cols].apply(lambda x: np.log(x + 1))\n",
    "#featData.describe().transpose()\n",
    "# Visualize the new log distributions\n",
    "#vs.distribution(features_log_transformed, transformed = True)\n",
    "\n",
    "#Applying a scaler to the data-set in order to normalise the date (0,1)\n",
    "#\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaledData=pd.DataFrame(data=featData)\n",
    "scaledData.head()\n",
    "scaledData[cols]=scaler.fit_transform(scaledData[cols])\n",
    "#scaledData.describe().transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmcgrath/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmcgrath/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=None,\n",
       "   estimator=Lasso(alpha=0.8, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=42,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "   n_jobs=1, scoring=None, step=1, verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lasso Regression\n",
    "#Feature selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.metrics import explained_variance_score,mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#Data has been normalised via MaxMinScaler\n",
    "##Lasso Regression\n",
    "#Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaledData, targData, test_size=0.20, random_state=42)\n",
    "#clf = linear_model.Lasso(alpha=0.5,max_iter=10,tol=0.01,random_state=42)\n",
    "clf = linear_model.Lasso(alpha=0.8,random_state=42,tol=0.0001,selection='cyclic',max_iter=1000)\n",
    "\n",
    "##Using the Select From Model Approach##\n",
    "model_select=SelectFromModel(clf,prefit=False,threshold=0.10)\n",
    "model_select.fit(X_train,y_train)\n",
    "#model_select.transform(X_train)\n",
    "\n",
    "##Using the Recursive Feature Selection Approach##\n",
    "model_select_rfe=RFE(clf,n_features_to_select=9)\n",
    "model_select_rfe.fit(X_train,y_train)\n",
    "#model_select_rfe.transform(X_train)\n",
    "\n",
    "##Using the Recursive Feature Selection Approach with Cross-Validation##\n",
    "model_select_RFECV=RFECV(clf)\n",
    "model_select_RFECV.fit(X_train,y_train)\n",
    "#model_select_RFECV.transform(X_train)\n",
    "\n",
    "#clf_lars=linear_model.LassoLarsCV()\n",
    "#clf_lars.fit(sfm.transform(X_train),y_train)\n",
    "\n",
    "#mean_squared_error(clf.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['wtd_entropy_atomic_mass', 'range_atomic_mass', 'range_atomic_radius',\n",
      "       'wtd_std_ThermalConductivity'],\n",
      "      dtype='object')\n",
      "GAP\n",
      "Index(['wtd_entropy_atomic_mass', 'range_atomic_mass', 'range_atomic_radius',\n",
      "       'entropy_ThermalConductivity', 'wtd_entropy_ThermalConductivity',\n",
      "       'range_ThermalConductivity', 'wtd_range_ThermalConductivity',\n",
      "       'std_ThermalConductivity', 'wtd_std_ThermalConductivity'],\n",
      "      dtype='object')\n",
      "Index(['wtd_entropy_atomic_mass', 'range_atomic_mass', 'range_atomic_radius',\n",
      "       'entropy_ThermalConductivity', 'wtd_entropy_ThermalConductivity',\n",
      "       'range_ThermalConductivity', 'wtd_range_ThermalConductivity',\n",
      "       'std_ThermalConductivity', 'wtd_std_ThermalConductivity'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "##Using the Select From Model Approach##\n",
    "print(X_train.columns[model_select.get_support()])\n",
    "##Using the Recursive Feature Selection Approach##\n",
    "print(\"GAP\")\n",
    "print(X_train.columns[model_select_rfe.get_support()])\n",
    "##Using the Recursive Feature Selection Approach with Cross-Validation##\n",
    "print(X_train.columns[model_select_RFECV.get_support()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e5025ead302e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_select_RFECV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "model_select_RFECV.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.337860107421875e-06"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Additional code block for defining functions\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import explained_variance_score,mean_squared_error\n",
    "#mean_squared_error(y_true,y_pred)\n",
    "#explained_variance_score(y_true,y_pred)\n",
    "\n",
    "# Training func\n",
    "def trainer(train,res,model):\n",
    "    #Note start time\n",
    "    st=time.time()\n",
    "    model.fit(train,res)\n",
    "    #Note time taken to train model\n",
    "    timeTaken=time.time()-st\n",
    "    return model\n",
    "\n",
    "# Testing func\n",
    "# Evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmcgrath/.local/lib/python3.5/site-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cf16ab941f9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mfig2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_atomic_mass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_Valence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m#featData.describe().transpose()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#Univariate visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#Accompanying visuals - Ensure all graph's are titled and axes labeled\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv('data/train.csv')\n",
    "data = pd.DataFrame(data)\n",
    "#Summary statistics\n",
    "#Target variables\n",
    "#Double [[]] wrapping ensure stays as pandas dataframe\n",
    "targData=data[['critical_temp']]\n",
    "fig=plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(targData['critical_temp'],bins=5)\n",
    "plt.title('Critical temperature distribution')\n",
    "plt.xlabel('Critical Temperature')\n",
    "plt.ylabel('#Chemical Materials')\n",
    "plt.show()\n",
    "\n",
    "#Visuals module - Look into this module for displaying data\n",
    "#vs.distribution(targData['critical_temp'])\n",
    "\n",
    "#Feature variables\n",
    "#Dropping the target variables from the data-set\n",
    "#featData=data.drop(['critical_temp'],axis=1)\n",
    "#ScatterPlot\n",
    "fig2=plt.figure\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(df['mean_atomic_mass'],df['mean_Valence'])\n",
    "#featData.describe().transpose()\n",
    "#Univariate visualization\n",
    "#Bivariate/Multivariate visalisations\n",
    "#Data clustering\n",
    "#list(featData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmcgrath/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "410.0245885313692"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creation of benchmark linear SVM\n",
    "#As suggested in Capstone Proposal feedback, it was propsed to create a\n",
    "#benchmark model in order to guage how the models\n",
    "#Importing required models from sklearn\n",
    "from sklearn import svm\n",
    "clf_svm=svm.SVR(C=1.0)\n",
    "clf_svm.fit(model_select_RFECV.transform(X_train), y_train)\n",
    "mean_squared_error(clf_svm.predict(model_select_RFECV.transform(X_test)),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmcgrath/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17010/17010 [==============================] - 3s 194us/step - loss: 718.0403\n",
      "Epoch 2/100\n",
      "17010/17010 [==============================] - 2s 115us/step - loss: 495.0749\n",
      "Epoch 3/100\n",
      "17010/17010 [==============================] - 2s 116us/step - loss: 439.1282\n",
      "Epoch 4/100\n",
      "17010/17010 [==============================] - 3s 151us/step - loss: 401.9616\n",
      "Epoch 5/100\n",
      "17010/17010 [==============================] - 3s 151us/step - loss: 380.6582\n",
      "Epoch 6/100\n",
      "17010/17010 [==============================] - 3s 154us/step - loss: 368.4849\n",
      "Epoch 7/100\n",
      "17010/17010 [==============================] - 2s 141us/step - loss: 361.4628\n",
      "Epoch 8/100\n",
      "17010/17010 [==============================] - 2s 139us/step - loss: 356.2898\n",
      "Epoch 9/100\n",
      "17010/17010 [==============================] - 2s 146us/step - loss: 350.9241\n",
      "Epoch 10/100\n",
      "17010/17010 [==============================] - 2s 131us/step - loss: 347.9927\n",
      "Epoch 11/100\n",
      "17010/17010 [==============================] - 2s 124us/step - loss: 343.5743\n",
      "Epoch 12/100\n",
      "17010/17010 [==============================] - 2s 119us/step - loss: 341.9806\n",
      "Epoch 13/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 337.5106\n",
      "Epoch 14/100\n",
      "17010/17010 [==============================] - 3s 162us/step - loss: 334.4930\n",
      "Epoch 15/100\n",
      "17010/17010 [==============================] - 2s 126us/step - loss: 332.5237\n",
      "Epoch 16/100\n",
      "17010/17010 [==============================] - 2s 117us/step - loss: 330.1892\n",
      "Epoch 17/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 327.7990\n",
      "Epoch 18/100\n",
      "17010/17010 [==============================] - 2s 120us/step - loss: 326.1195\n",
      "Epoch 19/100\n",
      "17010/17010 [==============================] - 2s 130us/step - loss: 324.0523\n",
      "Epoch 20/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 322.1097\n",
      "Epoch 21/100\n",
      "17010/17010 [==============================] - 2s 117us/step - loss: 319.4483\n",
      "Epoch 22/100\n",
      "17010/17010 [==============================] - 2s 120us/step - loss: 318.6292\n",
      "Epoch 23/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 316.7870 0s - loss: 316.5\n",
      "Epoch 24/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 314.8679\n",
      "Epoch 25/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 312.1700\n",
      "Epoch 26/100\n",
      "17010/17010 [==============================] - 2s 122us/step - loss: 310.4653\n",
      "Epoch 27/100\n",
      "17010/17010 [==============================] - 2s 123us/step - loss: 309.9288\n",
      "Epoch 28/100\n",
      "17010/17010 [==============================] - 2s 123us/step - loss: 308.8185\n",
      "Epoch 29/100\n",
      "17010/17010 [==============================] - 3s 161us/step - loss: 307.0005\n",
      "Epoch 30/100\n",
      "17010/17010 [==============================] - 3s 199us/step - loss: 305.1844\n",
      "Epoch 31/100\n",
      "17010/17010 [==============================] - 4s 224us/step - loss: 303.9421\n",
      "Epoch 32/100\n",
      "17010/17010 [==============================] - 2s 144us/step - loss: 302.4881\n",
      "Epoch 33/100\n",
      "17010/17010 [==============================] - 2s 122us/step - loss: 302.3995\n",
      "Epoch 34/100\n",
      "17010/17010 [==============================] - 2s 138us/step - loss: 300.8538\n",
      "Epoch 35/100\n",
      "17010/17010 [==============================] - 3s 150us/step - loss: 300.0101\n",
      "Epoch 36/100\n",
      "17010/17010 [==============================] - 2s 126us/step - loss: 298.3659\n",
      "Epoch 37/100\n",
      "17010/17010 [==============================] - 3s 147us/step - loss: 297.3578\n",
      "Epoch 38/100\n",
      "17010/17010 [==============================] - 2s 136us/step - loss: 297.1948\n",
      "Epoch 39/100\n",
      "17010/17010 [==============================] - 3s 156us/step - loss: 296.6066\n",
      "Epoch 40/100\n",
      "17010/17010 [==============================] - 2s 119us/step - loss: 294.3904\n",
      "Epoch 41/100\n",
      "17010/17010 [==============================] - 2s 122us/step - loss: 294.8611\n",
      "Epoch 42/100\n",
      "17010/17010 [==============================] - 2s 119us/step - loss: 292.7065\n",
      "Epoch 43/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 292.6282\n",
      "Epoch 44/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 291.9820\n",
      "Epoch 45/100\n",
      "17010/17010 [==============================] - 2s 123us/step - loss: 290.9126\n",
      "Epoch 46/100\n",
      "17010/17010 [==============================] - 2s 129us/step - loss: 289.9369\n",
      "Epoch 47/100\n",
      "17010/17010 [==============================] - 2s 127us/step - loss: 289.1691\n",
      "Epoch 48/100\n",
      "17010/17010 [==============================] - 2s 131us/step - loss: 287.7708\n",
      "Epoch 49/100\n",
      "17010/17010 [==============================] - 2s 145us/step - loss: 287.3957\n",
      "Epoch 50/100\n",
      "17010/17010 [==============================] - 2s 129us/step - loss: 287.1267\n",
      "Epoch 51/100\n",
      "17010/17010 [==============================] - 3s 152us/step - loss: 285.9668 0s -\n",
      "Epoch 52/100\n",
      "17010/17010 [==============================] - 2s 122us/step - loss: 284.7819\n",
      "Epoch 53/100\n",
      "17010/17010 [==============================] - 2s 127us/step - loss: 284.1516\n",
      "Epoch 54/100\n",
      "17010/17010 [==============================] - 2s 129us/step - loss: 284.3681\n",
      "Epoch 55/100\n",
      "17010/17010 [==============================] - 2s 135us/step - loss: 283.8751\n",
      "Epoch 56/100\n",
      "17010/17010 [==============================] - 2s 133us/step - loss: 283.0691\n",
      "Epoch 57/100\n",
      "17010/17010 [==============================] - 3s 163us/step - loss: 282.6491\n",
      "Epoch 58/100\n",
      "17010/17010 [==============================] - 3s 176us/step - loss: 282.8126\n",
      "Epoch 59/100\n",
      "17010/17010 [==============================] - 3s 154us/step - loss: 281.3997\n",
      "Epoch 60/100\n",
      "17010/17010 [==============================] - 3s 147us/step - loss: 280.8383\n",
      "Epoch 61/100\n",
      "17010/17010 [==============================] - 2s 140us/step - loss: 281.1483\n",
      "Epoch 62/100\n",
      "17010/17010 [==============================] - 2s 123us/step - loss: 280.7011\n",
      "Epoch 63/100\n",
      "17010/17010 [==============================] - 2s 139us/step - loss: 279.1291\n",
      "Epoch 64/100\n",
      "17010/17010 [==============================] - 2s 124us/step - loss: 278.5175\n",
      "Epoch 65/100\n",
      "17010/17010 [==============================] - 3s 148us/step - loss: 278.6323\n",
      "Epoch 66/100\n",
      "17010/17010 [==============================] - 2s 143us/step - loss: 276.9455\n",
      "Epoch 67/100\n",
      "17010/17010 [==============================] - 3s 182us/step - loss: 277.3652\n",
      "Epoch 68/100\n",
      "17010/17010 [==============================] - 3s 190us/step - loss: 276.2783\n",
      "Epoch 69/100\n",
      "17010/17010 [==============================] - 2s 141us/step - loss: 276.0892\n",
      "Epoch 70/100\n",
      "17010/17010 [==============================] - 2s 126us/step - loss: 276.7800\n",
      "Epoch 71/100\n",
      "17010/17010 [==============================] - 2s 142us/step - loss: 275.0894\n",
      "Epoch 72/100\n",
      "17010/17010 [==============================] - 2s 141us/step - loss: 274.1751\n",
      "Epoch 73/100\n",
      "17010/17010 [==============================] - 2s 129us/step - loss: 274.5893\n",
      "Epoch 74/100\n",
      "17010/17010 [==============================] - 2s 135us/step - loss: 273.5092\n",
      "Epoch 75/100\n",
      "17010/17010 [==============================] - 2s 130us/step - loss: 273.0280\n",
      "Epoch 76/100\n",
      "17010/17010 [==============================] - 3s 148us/step - loss: 271.7461\n",
      "Epoch 77/100\n",
      "17010/17010 [==============================] - 2s 114us/step - loss: 273.4449\n",
      "Epoch 78/100\n",
      "17010/17010 [==============================] - 2s 107us/step - loss: 271.4634\n",
      "Epoch 79/100\n",
      "17010/17010 [==============================] - 2s 130us/step - loss: 272.0532\n",
      "Epoch 80/100\n",
      "17010/17010 [==============================] - 2s 114us/step - loss: 271.1466\n",
      "Epoch 81/100\n",
      "17010/17010 [==============================] - 2s 114us/step - loss: 270.0012\n",
      "Epoch 82/100\n",
      "17010/17010 [==============================] - 2s 102us/step - loss: 270.3828\n",
      "Epoch 83/100\n",
      "17010/17010 [==============================] - 2s 106us/step - loss: 270.4946\n",
      "Epoch 84/100\n",
      "17010/17010 [==============================] - 2s 102us/step - loss: 269.9774\n",
      "Epoch 85/100\n",
      "17010/17010 [==============================] - 2s 104us/step - loss: 268.2901 0s - l\n",
      "Epoch 86/100\n",
      "17010/17010 [==============================] - 2s 104us/step - loss: 269.7051\n",
      "Epoch 87/100\n",
      "17010/17010 [==============================] - 2s 102us/step - loss: 268.0107\n",
      "Epoch 88/100\n",
      "17010/17010 [==============================] - 2s 102us/step - loss: 268.9884\n",
      "Epoch 89/100\n",
      "17010/17010 [==============================] - 2s 102us/step - loss: 267.2855\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17010/17010 [==============================] - 2s 102us/step - loss: 268.3284\n",
      "Epoch 91/100\n",
      "17010/17010 [==============================] - 2s 102us/step - loss: 266.7056\n",
      "Epoch 92/100\n",
      "17010/17010 [==============================] - 2s 101us/step - loss: 266.9421\n",
      "Epoch 93/100\n",
      "17010/17010 [==============================] - 2s 103us/step - loss: 267.2265\n",
      "Epoch 94/100\n",
      "17010/17010 [==============================] - 2s 102us/step - loss: 267.5374\n",
      "Epoch 95/100\n",
      "17010/17010 [==============================] - 2s 99us/step - loss: 266.5442\n",
      "Epoch 96/100\n",
      "17010/17010 [==============================] - 2s 99us/step - loss: 266.1841\n",
      "Epoch 97/100\n",
      "17010/17010 [==============================] - 2s 100us/step - loss: 266.6757\n",
      "Epoch 98/100\n",
      "17010/17010 [==============================] - 2s 99us/step - loss: 266.2085\n",
      "Epoch 99/100\n",
      "17010/17010 [==============================] - 2s 99us/step - loss: 265.9167\n",
      "Epoch 100/100\n",
      "17010/17010 [==============================] - 2s 100us/step - loss: 265.5802\n",
      "105.8855405985867 243.93773813089808\n"
     ]
    }
   ],
   "source": [
    "#Importing required models from sklearn\n",
    "from numpy.core.umath_tests import inner1d\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#Training the models\n",
    "#Random Forest\n",
    "clf_rf=RandomForestRegressor(n_estimators=10,max_depth=20,random_state=42)\n",
    "clf_rf.fit(model_select_RFECV.transform(X_train), y_train)\n",
    "a=mean_squared_error(clf_rf.predict(model_select_RFECV.transform(X_test)),y_test)\n",
    "#Neural Network\n",
    "from sklearn import preprocessing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Start neural network\n",
    "##https://chrisalbon.com/deep_learning/keras/feedforward_neural_network_for_regression/\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=32, activation='relu', input_shape=(model_select_RFECV.transform(X_train).shape[1],)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=32, activation='relu'))\n",
    "\n",
    "# Add fully connected layer with no activation function\n",
    "network.add(layers.Dense(units=1))\n",
    "network.compile(loss='mse',optimizer='RMSprop')\n",
    "network.fit(model_select_RFECV.transform(X_train), y_train, epochs=100,batch_size=10)\n",
    "b=mean_squared_error(network.predict(model_select_RFECV.transform(X_test)),y_test)\n",
    "print(a,b)\n",
    "#Validating the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refining the model prior to testing\n",
    "#Evaluation paraemters etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the final results\n",
    "#Accuracy - Comparsion to benchmark models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
