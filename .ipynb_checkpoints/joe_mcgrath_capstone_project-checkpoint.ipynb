{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Juypter Notebook for Joe McGrath's submission for the Udacity Machine Learning Engineer nanodegree program.\n",
    "This file contains the relevant code-blocks, assiocated comments and visual aids to be used in conjunction with the written PDF piece.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intro code cell, in here the required libaries will be imported\n",
    "#Comments etc.\n",
    "#Data imported, results from other models saved for future reference\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#import visuals as vs\n",
    "%matplotlib inline\n",
    "#Plotting libaries\n",
    "#Machine Learning libaries \n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "#Summary statistics\n",
    "#Target variables\n",
    "#Double [[]] wrapping ensure stays as pandas dataframe\n",
    "targData=data[['critical_temp']]\n",
    "#Feature variables\n",
    "#Dropping the target variables from the data-set\n",
    "featData=data.drop(['critical_temp'],axis=1)\n",
    "featData=featData.drop(['number_of_elements'],axis=1)\n",
    "#featData.describe().transpose()\n",
    "\n",
    "#Data Transformation\n",
    "#Applying lograthmic and Scaling to the data-set prior to training/testing\n",
    "#Applying lograthmic transformation to the data-set\n",
    "cols=list(featData)\n",
    "featData[cols] = featData[cols].apply(lambda x: np.log(x + 1))\n",
    "#featData.describe().transpose()\n",
    "# Visualize the new log distributions\n",
    "#vs.distribution(features_log_transformed, transformed = True)\n",
    "\n",
    "#Applying a scaler to the data-set in order to normalise the date (0,1)\n",
    "#\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaledData=pd.DataFrame(data=featData)\n",
    "scaledData.head()\n",
    "scaledData[cols]=scaler.fit_transform(scaledData[cols])\n",
    "#scaledData.describe().transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmcgrath/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.           0.          -0.           0.           0.\n",
      "  34.06125958   0.          -0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.          -0.           0.           0.\n",
      "   0.           0.          -0.           0.           0.\n",
      "   0.           0.          -0.           0.           0.\n",
      "  -0.          -0.          -0.          -0.           0.\n",
      "   0.          -0.          -0.          -0.          -0.\n",
      "  -0.           0.          -0.          -0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "  -0.          -0.          -0.          -0.           0.\n",
      "   7.25605385  -0.          -0.          -1.04721293  -0.\n",
      "   0.           0.          -0.          -0.           0.\n",
      "  -0.           0.           6.84404544   0.          18.90928483\n",
      "  -1.67306792 -53.15729293  -0.          -0.           0.\n",
      "   0.          -0.          -0.          -0.         -21.60533595]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmcgrath/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "490.08879746288557"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lasso Regression\n",
    "#Feature selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.metrics import explained_variance_score,mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "#Data has been normalised via MaxMinScaler\n",
    "##Lasso Regression\n",
    "#Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaledData, targData, test_size=0.20, random_state=42)\n",
    "#clf = linear_model.Lasso(alpha=0.5,max_iter=10,tol=0.01,random_state=42)\n",
    "clf = linear_model.Lasso(alpha=0.5,random_state=42)\n",
    "rfe = RFE(clf, 3)\n",
    "rfe.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.coef_)\n",
    "\n",
    "sfm = SelectFromModel(clf, threshold=0.25)\n",
    "sfm.fit(X_train, y_train)\n",
    "n_features = sfm.transform(X_train).shape[1]\n",
    "while n_features > 12:\n",
    "    sfm.threshold += 0.1\n",
    "    X_transform = sfm.transform(X_train)\n",
    "    n_features = X_transform.shape[1]\n",
    "\n",
    "\n",
    "#clf_lars=linear_model.LassoLarsCV()\n",
    "#clf_lars.fit(sfm.transform(X_train),y_train)\n",
    "\n",
    "#mean_squared_error(clf.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>mean_Valence</th>\n",
       "      <th>std_FusionHeat</th>\n",
       "      <th>wtd_range_ThermalConductivity</th>\n",
       "      <th>wtd_entropy_FusionHeat</th>\n",
       "      <th>wtd_std_ThermalConductivity</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13976</th>\n",
       "      <td>0.761781</td>\n",
       "      <td>0.259526</td>\n",
       "      <td>0.729716</td>\n",
       "      <td>0.316084</td>\n",
       "      <td>0.546414</td>\n",
       "      <td>0.462708</td>\n",
       "      <td>0.238552</td>\n",
       "      <td>0.379711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>0.326038</td>\n",
       "      <td>0.216441</td>\n",
       "      <td>0.350220</td>\n",
       "      <td>0.449889</td>\n",
       "      <td>0.858678</td>\n",
       "      <td>0.673525</td>\n",
       "      <td>0.979988</td>\n",
       "      <td>0.687665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.319542</td>\n",
       "      <td>0.199522</td>\n",
       "      <td>0.382767</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.755255</td>\n",
       "      <td>0.758892</td>\n",
       "      <td>0.953752</td>\n",
       "      <td>0.854041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>0.350537</td>\n",
       "      <td>0.259939</td>\n",
       "      <td>0.350220</td>\n",
       "      <td>0.434629</td>\n",
       "      <td>0.677384</td>\n",
       "      <td>0.694111</td>\n",
       "      <td>0.919829</td>\n",
       "      <td>0.658313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13540</th>\n",
       "      <td>0.883959</td>\n",
       "      <td>0.394739</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>0.686901</td>\n",
       "      <td>0.672781</td>\n",
       "      <td>0.432072</td>\n",
       "      <td>0.786981</td>\n",
       "      <td>0.613041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wtd_mean_Valence  wtd_std_Valence  mean_Valence  std_FusionHeat  \\\n",
       "13976          0.761781         0.259526      0.729716        0.316084   \n",
       "1710           0.326038         0.216441      0.350220        0.449889   \n",
       "369            0.319542         0.199522      0.382767        0.429630   \n",
       "1698           0.350537         0.259939      0.350220        0.434629   \n",
       "13540          0.883959         0.394739      0.792481        0.686901   \n",
       "\n",
       "       wtd_range_ThermalConductivity  wtd_entropy_FusionHeat  \\\n",
       "13976                       0.546414                0.462708   \n",
       "1710                        0.858678                0.673525   \n",
       "369                         0.755255                0.758892   \n",
       "1698                        0.677384                0.694111   \n",
       "13540                       0.672781                0.432072   \n",
       "\n",
       "       wtd_std_ThermalConductivity  wtd_entropy_atomic_mass  \n",
       "13976                     0.238552                 0.379711  \n",
       "1710                      0.979988                 0.687665  \n",
       "369                       0.953752                 0.854041  \n",
       "1698                      0.919829                 0.658313  \n",
       "13540                     0.786981                 0.613041  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://blog.datadive.net/selecting-good-features-part-ii-linear-models-and-regularization/\n",
    "def pretty_print_linear(coefs, names = None, sort = False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name)\n",
    "                                   for coef, name in lst)\n",
    "\n",
    "#pretty_print_linear(clf.coef_,cols,sort=True)\n",
    "a=zip(clf.coef_, cols)\n",
    "sorted(a)\n",
    "\n",
    "\n",
    "selData_train=X_train[['wtd_mean_Valence','wtd_std_Valence','mean_Valence','std_FusionHeat','wtd_range_ThermalConductivity','wtd_entropy_FusionHeat','wtd_std_ThermalConductivity','wtd_entropy_atomic_mass']]\n",
    "selData_test=X_test[['wtd_mean_Valence','wtd_std_Valence','mean_Valence','std_FusionHeat','wtd_range_ThermalConductivity','wtd_entropy_FusionHeat','wtd_std_ThermalConductivity','wtd_entropy_atomic_mass']]\n",
    "selData_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.337860107421875e-06"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Additional code block for defining functions\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import explained_variance_score,mean_squared_error\n",
    "#mean_squared_error(y_true,y_pred)\n",
    "#explained_variance_score(y_true,y_pred)\n",
    "\n",
    "# Training func\n",
    "def trainer(train,res,model):\n",
    "    #Note start time\n",
    "    st=time.time()\n",
    "    model.fit(train,res)\n",
    "    #Note time taken to train model\n",
    "    timeTaken=time.time()-st\n",
    "    return model\n",
    "\n",
    "# Testing func\n",
    "# Evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmcgrath/.local/lib/python3.5/site-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cf16ab941f9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mfig2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_atomic_mass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_Valence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m#featData.describe().transpose()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#Univariate visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#Accompanying visuals - Ensure all graph's are titled and axes labeled\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv('data/train.csv')\n",
    "data = pd.DataFrame(data)\n",
    "#Summary statistics\n",
    "#Target variables\n",
    "#Double [[]] wrapping ensure stays as pandas dataframe\n",
    "targData=data[['critical_temp']]\n",
    "fig=plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(targData['critical_temp'],bins=5)\n",
    "plt.title('Critical temperature distribution')\n",
    "plt.xlabel('Critical Temperature')\n",
    "plt.ylabel('#Chemical Materials')\n",
    "plt.show()\n",
    "\n",
    "#Visuals module - Look into this module for displaying data\n",
    "#vs.distribution(targData['critical_temp'])\n",
    "\n",
    "#Feature variables\n",
    "#Dropping the target variables from the data-set\n",
    "#featData=data.drop(['critical_temp'],axis=1)\n",
    "#ScatterPlot\n",
    "fig2=plt.figure\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(df['mean_atomic_mass'],df['mean_Valence'])\n",
    "#featData.describe().transpose()\n",
    "#Univariate visualization\n",
    "#Bivariate/Multivariate visalisations\n",
    "#Data clustering\n",
    "#list(featData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmcgrath/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "458.07183154301333"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creation of benchmark linear SVM\n",
    "#As suggested in Capstone Proposal feedback, it was propsed to create a\n",
    "#benchmark model in order to guage how the models\n",
    "#Importing required models from sklearn\n",
    "from sklearn import svm\n",
    "clf_svm=svm.SVR(C=1.0)\n",
    "clf_svm.fit(selData_train, y_train)\n",
    "\n",
    "mean_squared_error(clf_svm.predict(selData_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmcgrath/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17010/17010 [==============================] - 2s 131us/step - loss: 379.4804\n",
      "Epoch 2/100\n",
      "17010/17010 [==============================] - 2s 116us/step - loss: 375.5469\n",
      "Epoch 3/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 370.4607\n",
      "Epoch 4/100\n",
      "17010/17010 [==============================] - 2s 116us/step - loss: 367.4392\n",
      "Epoch 5/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 363.4814\n",
      "Epoch 6/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 359.2966 0s - los\n",
      "Epoch 7/100\n",
      "17010/17010 [==============================] - 2s 119us/step - loss: 355.5050\n",
      "Epoch 8/100\n",
      "17010/17010 [==============================] - 2s 120us/step - loss: 350.0736\n",
      "Epoch 9/100\n",
      "17010/17010 [==============================] - 2s 119us/step - loss: 347.5650\n",
      "Epoch 10/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 343.8886\n",
      "Epoch 11/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 340.9306\n",
      "Epoch 12/100\n",
      "17010/17010 [==============================] - 2s 119us/step - loss: 337.8440\n",
      "Epoch 13/100\n",
      "17010/17010 [==============================] - 2s 119us/step - loss: 334.5939\n",
      "Epoch 14/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 331.0758\n",
      "Epoch 15/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 329.3257\n",
      "Epoch 16/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 327.4799\n",
      "Epoch 17/100\n",
      "17010/17010 [==============================] - 2s 124us/step - loss: 325.7467\n",
      "Epoch 18/100\n",
      "17010/17010 [==============================] - 2s 122us/step - loss: 323.5136\n",
      "Epoch 19/100\n",
      "17010/17010 [==============================] - 2s 120us/step - loss: 322.3350\n",
      "Epoch 20/100\n",
      "17010/17010 [==============================] - 2s 122us/step - loss: 320.9109\n",
      "Epoch 21/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 318.7534\n",
      "Epoch 22/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 319.3077\n",
      "Epoch 23/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 317.4079\n",
      "Epoch 24/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 316.2406\n",
      "Epoch 25/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 314.2986 0s \n",
      "Epoch 26/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 314.7216\n",
      "Epoch 27/100\n",
      "17010/17010 [==============================] - 2s 122us/step - loss: 313.6549\n",
      "Epoch 28/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 311.6272\n",
      "Epoch 29/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 311.5339\n",
      "Epoch 30/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 309.2365\n",
      "Epoch 31/100\n",
      "17010/17010 [==============================] - 2s 123us/step - loss: 308.0113\n",
      "Epoch 32/100\n",
      "17010/17010 [==============================] - 2s 123us/step - loss: 306.7801\n",
      "Epoch 33/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 307.1639\n",
      "Epoch 34/100\n",
      "17010/17010 [==============================] - 2s 122us/step - loss: 305.9051\n",
      "Epoch 35/100\n",
      "17010/17010 [==============================] - 2s 123us/step - loss: 305.0048\n",
      "Epoch 36/100\n",
      "17010/17010 [==============================] - 2s 122us/step - loss: 303.4080\n",
      "Epoch 37/100\n",
      "17010/17010 [==============================] - 2s 126us/step - loss: 303.3773\n",
      "Epoch 38/100\n",
      "17010/17010 [==============================] - 2s 124us/step - loss: 302.5201\n",
      "Epoch 39/100\n",
      "17010/17010 [==============================] - 2s 143us/step - loss: 301.1999\n",
      "Epoch 40/100\n",
      "17010/17010 [==============================] - 2s 116us/step - loss: 299.9979\n",
      "Epoch 41/100\n",
      "17010/17010 [==============================] - 2s 118us/step - loss: 299.5324\n",
      "Epoch 42/100\n",
      "17010/17010 [==============================] - 3s 153us/step - loss: 298.9364\n",
      "Epoch 43/100\n",
      "17010/17010 [==============================] - 3s 184us/step - loss: 298.6858\n",
      "Epoch 44/100\n",
      "17010/17010 [==============================] - 3s 199us/step - loss: 297.6062\n",
      "Epoch 45/100\n",
      "17010/17010 [==============================] - 2s 132us/step - loss: 297.1667\n",
      "Epoch 46/100\n",
      "17010/17010 [==============================] - 2s 124us/step - loss: 297.0225\n",
      "Epoch 47/100\n",
      "17010/17010 [==============================] - 3s 157us/step - loss: 295.9093\n",
      "Epoch 48/100\n",
      "17010/17010 [==============================] - 2s 115us/step - loss: 294.4471\n",
      "Epoch 49/100\n",
      "17010/17010 [==============================] - 2s 121us/step - loss: 294.0308\n",
      "Epoch 50/100\n",
      "17010/17010 [==============================] - 2s 120us/step - loss: 293.2884\n",
      "Epoch 51/100\n",
      "17010/17010 [==============================] - 3s 152us/step - loss: 292.7578\n",
      "Epoch 52/100\n",
      "17010/17010 [==============================] - 4s 226us/step - loss: 292.4943\n",
      "Epoch 53/100\n",
      "17010/17010 [==============================] - 4s 242us/step - loss: 292.4679\n",
      "Epoch 54/100\n",
      "17010/17010 [==============================] - 3s 152us/step - loss: 291.9573\n",
      "Epoch 55/100\n",
      "17010/17010 [==============================] - 2s 129us/step - loss: 291.3182\n",
      "Epoch 56/100\n",
      "17010/17010 [==============================] - 3s 149us/step - loss: 290.5218\n",
      "Epoch 57/100\n",
      "17010/17010 [==============================] - 3s 185us/step - loss: 290.3079\n",
      "Epoch 58/100\n",
      "17010/17010 [==============================] - 3s 201us/step - loss: 291.0659\n",
      "Epoch 59/100\n",
      "17010/17010 [==============================] - 3s 181us/step - loss: 288.9003\n",
      "Epoch 60/100\n",
      "17010/17010 [==============================] - 2s 126us/step - loss: 288.7276\n",
      "Epoch 61/100\n",
      "17010/17010 [==============================] - 3s 203us/step - loss: 288.3438\n",
      "Epoch 62/100\n",
      "17010/17010 [==============================] - 4s 239us/step - loss: 288.0537\n",
      "Epoch 63/100\n",
      "17010/17010 [==============================] - 3s 195us/step - loss: 287.3270\n",
      "Epoch 64/100\n",
      "17010/17010 [==============================] - 3s 182us/step - loss: 286.1856\n",
      "Epoch 65/100\n",
      "17010/17010 [==============================] - 4s 247us/step - loss: 286.5478\n",
      "Epoch 66/100\n",
      "17010/17010 [==============================] - 3s 166us/step - loss: 285.9007\n",
      "Epoch 67/100\n",
      "17010/17010 [==============================] - 3s 150us/step - loss: 285.7485\n",
      "Epoch 68/100\n",
      "17010/17010 [==============================] - 2s 130us/step - loss: 284.9729\n",
      "Epoch 69/100\n",
      "17010/17010 [==============================] - 2s 117us/step - loss: 284.4572\n",
      "Epoch 70/100\n",
      "17010/17010 [==============================] - 2s 111us/step - loss: 284.5910\n",
      "Epoch 71/100\n",
      "17010/17010 [==============================] - 2s 111us/step - loss: 284.4528\n",
      "Epoch 72/100\n",
      "17010/17010 [==============================] - 2s 114us/step - loss: 284.5803\n",
      "Epoch 73/100\n",
      "17010/17010 [==============================] - 2s 129us/step - loss: 283.0780\n",
      "Epoch 74/100\n",
      "17010/17010 [==============================] - 3s 168us/step - loss: 283.7118\n",
      "Epoch 75/100\n",
      "17010/17010 [==============================] - 3s 157us/step - loss: 282.2363\n",
      "Epoch 76/100\n",
      "17010/17010 [==============================] - 2s 139us/step - loss: 282.4943\n",
      "Epoch 77/100\n",
      "17010/17010 [==============================] - 3s 169us/step - loss: 282.9133\n",
      "Epoch 78/100\n",
      "17010/17010 [==============================] - 3s 168us/step - loss: 282.1160\n",
      "Epoch 79/100\n",
      "17010/17010 [==============================] - 2s 136us/step - loss: 281.7275\n",
      "Epoch 80/100\n",
      "17010/17010 [==============================] - 4s 206us/step - loss: 281.2421\n",
      "Epoch 81/100\n",
      "17010/17010 [==============================] - 3s 164us/step - loss: 279.5126\n",
      "Epoch 82/100\n",
      "17010/17010 [==============================] - 4s 242us/step - loss: 281.0473\n",
      "Epoch 83/100\n",
      "17010/17010 [==============================] - 4s 247us/step - loss: 280.6154\n",
      "Epoch 84/100\n",
      "17010/17010 [==============================] - 4s 230us/step - loss: 279.5095\n",
      "Epoch 85/100\n",
      "17010/17010 [==============================] - 3s 176us/step - loss: 279.0914\n",
      "Epoch 86/100\n",
      "17010/17010 [==============================] - 3s 152us/step - loss: 279.7662\n",
      "Epoch 87/100\n",
      "17010/17010 [==============================] - 2s 142us/step - loss: 279.3076\n",
      "Epoch 88/100\n",
      "17010/17010 [==============================] - 2s 134us/step - loss: 278.8264\n",
      "Epoch 89/100\n",
      "17010/17010 [==============================] - 2s 134us/step - loss: 278.0165\n",
      "Epoch 90/100\n",
      "17010/17010 [==============================] - 2s 137us/step - loss: 277.9142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "17010/17010 [==============================] - 2s 115us/step - loss: 277.6608\n",
      "Epoch 92/100\n",
      "17010/17010 [==============================] - 2s 115us/step - loss: 277.2154\n",
      "Epoch 93/100\n",
      "17010/17010 [==============================] - 2s 117us/step - loss: 276.5315\n",
      "Epoch 94/100\n",
      "17010/17010 [==============================] - 2s 114us/step - loss: 276.1912\n",
      "Epoch 95/100\n",
      "17010/17010 [==============================] - 2s 114us/step - loss: 275.5295\n",
      "Epoch 96/100\n",
      "17010/17010 [==============================] - 2s 114us/step - loss: 276.7216 0s - loss: 277.2\n",
      "Epoch 97/100\n",
      "17010/17010 [==============================] - 2s 115us/step - loss: 276.2582\n",
      "Epoch 98/100\n",
      "17010/17010 [==============================] - 2s 113us/step - loss: 276.3075\n",
      "Epoch 99/100\n",
      "17010/17010 [==============================] - 2s 114us/step - loss: 276.1687\n",
      "Epoch 100/100\n",
      "17010/17010 [==============================] - 2s 114us/step - loss: 275.5315\n",
      "110.28264801570364 246.58741709267335\n"
     ]
    }
   ],
   "source": [
    "#Importing required models from sklearn\n",
    "from numpy.core.umath_tests import inner1d\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#Training the models\n",
    "#Random Forest\n",
    "clf_rf=RandomForestRegressor(n_estimators=10,max_depth=20,random_state=42)\n",
    "clf_rf.fit(selData_train, y_train)\n",
    "a=mean_squared_error(clf_rf.predict(selData_test),y_test)\n",
    "#Neural Network\n",
    "from sklearn import preprocessing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Start neural network\n",
    "##https://chrisalbon.com/deep_learning/keras/feedforward_neural_network_for_regression/\n",
    "#network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "#network.add(layers.Dense(units=32, activation='relu', input_shape=(selData_test.shape[1],)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "#network.add(layers.Dense(units=32, activation='relu'))\n",
    "\n",
    "# Add fully connected layer with no activation function\n",
    "#network.add(layers.Dense(units=1))\n",
    "network.compile(loss='mse',optimizer='RMSprop')\n",
    "network.fit(selData_train, y_train, epochs=100,batch_size=10)\n",
    "b=mean_squared_error(network.predict(selData_test),y_test)\n",
    "print(a,b)\n",
    "#Validating the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refining the model prior to testing\n",
    "#Evaluation paraemters etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the final results\n",
    "#Accuracy - Comparsion to benchmark models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
